In this little example, we're going to see some of the problems that regularly appear in tokenization. Tokenization may seem simple, but it's harder than it first appears. Why is it so hard? Punctuations, contractions (like don't, won't and would've) get in the way. What do you do when you have #hashtags, @TwitterHandles, or https://urls.com? Different packages will make different decisions on when to split text apart, and when not to.
